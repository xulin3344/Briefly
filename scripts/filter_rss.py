#!/usr/bin/env python3
"""
å…³é”®è¯ RSS ç­›é€‰è„šæœ¬
åŠŸèƒ½ï¼šè§£æ RSS æºï¼ŒæŒ‰å…³é”®è¯ç­›é€‰æ–‡ç« 
- åŒ…å«è¯ï¼šå¿…é¡»åŒ…å« 'è‡ªåŠ¨é©¾é©¶' æˆ– 'æ— äººæœº'
- æ’é™¤è¯ï¼šä¸èƒ½åŒ…å« 'ä»£ç†' æˆ– 'åŠ ç›Ÿ'
- è¾“å‡ºï¼šæ‰“å°åŒ¹é…æˆåŠŸçš„æ–‡ç« æ ‡é¢˜å’Œé“¾æ¥ï¼ˆå»é‡ï¼‰
"""

import feedparser
from urllib.parse import urlparse
import hashlib
from typing import Set, Tuple


class KeywordFilter:
    def __init__(self, include_keywords: list, exclude_keywords: list):
        self.include_keywords = [kw.lower() for kw in include_keywords]
        self.exclude_keywords = [kw.lower() for kw in exclude_keywords]

    def matches(self, title: str, summary: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ–‡ç« æ˜¯å¦åŒ¹é…ç­›é€‰æ¡ä»¶
        è¿”å›: (æ˜¯å¦åŒ¹é…, åŒ¹é…çš„å…³é”®è¯)
        """
        text = f"{title} {summary}".lower()

        # æ£€æŸ¥æ’é™¤è¯
        for exclude_kw in self.exclude_keywords:
            if exclude_kw in text:
                return False, exclude_kw

        # æ£€æŸ¥åŒ…å«è¯ï¼ˆå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªï¼‰
        for include_kw in self.include_keywords:
            if include_kw in text:
                return True, include_kw

        return False, ""

    def should_include(self, title: str, summary: str) -> bool:
        """åˆ¤æ–­æ–‡ç« æ˜¯å¦åº”è¯¥åŒ…å«"""
        match, _ = self.matches(title, summary)
        return match


def parse_rss(url: str) -> list:
    """è§£æ RSS æº"""
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨è§£æ: {url}")
    print(f"{'='*60}")

    feed = feedparser.parse(url)

    if feed.bozo:
        print(f"âš ï¸  RSS è§£æè­¦å‘Š: {feed.bozo_exception}")

    if not hasattr(feed, 'entries') or len(feed.entries) == 0:
        print(f"âŒ æœªèƒ½è·å–åˆ°æ–‡ç« ")
        return []

    print(f"âœ… æˆåŠŸè·å– {len(feed.entries)} ç¯‡æ–‡ç« \n")
    return feed.entries


def extract_article_info(entry) -> Tuple[str, str, str]:
    """æå–æ–‡ç« ä¿¡æ¯"""
    title = entry.get('title', 'æ— æ ‡é¢˜')

    summary = ''
    if hasattr(entry, 'summary'):
        summary = entry.summary
    elif hasattr(entry, 'description'):
        summary = entry.description

    link = ''
    if hasattr(entry, 'link'):
        link = entry.link
        if isinstance(link, list):
            link = link[0]

    return title, summary, link


def get_article_hash(title: str, link: str) -> str:
    """ç”Ÿæˆæ–‡ç« å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºå»é‡ï¼‰"""
    content = f"{title.lower().strip()}|{link.lower().strip()}"
    return hashlib.md5(content.encode('utf-8')).hexdigest()[:8]


def filter_rss(rss_urls: list, include_keywords: list, exclude_keywords: list) -> list:
    """
    ç­›é€‰ RSS æ–‡ç« 

    Args:
        rss_urls: RSS æºåˆ—è¡¨
        include_keywords: å¿…é¡»åŒ…å«çš„å…³é”®è¯åˆ—è¡¨
        exclude_keywords: ä¸èƒ½åŒ…å«çš„å…³é”®è¯åˆ—è¡¨

    Returns:
        åŒ¹é…çš„æ–‡ç« åˆ—è¡¨
    """
    filter_obj = KeywordFilter(include_keywords, exclude_keywords)
    seen_hashes: Set[str] = set()
    matched_articles = []

    print(f"\n{'ğŸ” ç­›é€‰é…ç½®'}")
    print(f"åŒ…å«è¯: {include_keywords}")
    print(f"æ’é™¤è¯: {exclude_keywords}")
    print(f"{'â”€'*40}")

    for rss_url in rss_urls:
        entries = parse_rss(rss_url)

        for entry in entries:
            title, summary, link = extract_article_info(entry)

            if not link:
                continue

            article_hash = get_article_hash(title, link)
            if article_hash in seen_hashes:
                continue

            if filter_obj.should_include(title, summary):
                seen_hashes.add(article_hash)
                matched_articles.append({
                    'title': title,
                    'link': link,
                    'source': urlparse(rss_url).netloc
                })

    return matched_articles


def print_results(articles: list):
    """æ‰“å°ç­›é€‰ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ç­›é€‰ç»“æœ: å…±æ‰¾åˆ° {len(articles)} ç¯‡åŒ¹é…çš„æ–‡ç« ")
    print(f"{'='*60}\n")

    if not articles:
        print("æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ç« ")
        return

    for i, article in enumerate(articles, 1):
        print(f"{i:3}. {article['title'][:50]}...")
        print(f"    ğŸ”— {article['link'][:80]}")
        print(f"    ğŸ“° æ¥æº: {article['source']}")
        print()


def main():
    # RSS æºé…ç½®
    RSS_SOURCES = [
        "https://36kr.com/feed/",
        "https://www.sspai.com/feed",
        "https://www.techcrunch.com/feed/",
        # åœ¨è¿™é‡Œæ·»åŠ æ›´å¤š RSS æº
    ]

    # åŒ…å«è¯ï¼ˆå¿…é¡»åŒ…å«ï¼‰
    INCLUDE_KEYWORDS = [
        "è‡ªåŠ¨é©¾é©¶",
        "æ— äººæœº",
    ]

    # æ’é™¤è¯ï¼ˆä¸èƒ½åŒ…å«ï¼‰
    EXCLUDE_KEYWORDS = [
        "ä»£ç†",
        "åŠ ç›Ÿ",
    ]

    # ç­›é€‰å¹¶æ‰“å°ç»“æœ
    articles = filter_rss(RSS_SOURCES, INCLUDE_KEYWORDS, EXCLUDE_KEYWORDS)
    print_results(articles)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    if articles:
        with open('filtered_articles.txt', 'w', encoding='utf-8') as f:
            for article in articles:
                f.write(f"{article['title']}\n")
                f.write(f"{article['link']}\n")
                f.write(f"{'â”€'*40}\n")
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: filtered_articles.txt")


if __name__ == "__main__":
    main()
